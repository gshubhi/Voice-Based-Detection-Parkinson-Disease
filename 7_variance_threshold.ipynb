{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "56bc1197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>189</td>\n",
       "      <td>5.016506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>47</td>\n",
       "      <td>5.341693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>188</td>\n",
       "      <td>5.665210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>43</td>\n",
       "      <td>6.671609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>50</td>\n",
       "      <td>7.573311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>40</td>\n",
       "      <td>8.600988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>48</td>\n",
       "      <td>8.970383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32</td>\n",
       "      <td>10.101856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>42</td>\n",
       "      <td>10.697524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>39</td>\n",
       "      <td>12.165576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>49</td>\n",
       "      <td>13.318558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>34</td>\n",
       "      <td>15.074382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29</td>\n",
       "      <td>16.622048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38</td>\n",
       "      <td>17.024494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>41</td>\n",
       "      <td>17.610304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31</td>\n",
       "      <td>18.511246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27</td>\n",
       "      <td>18.682756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26</td>\n",
       "      <td>20.194909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30</td>\n",
       "      <td>20.316810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28</td>\n",
       "      <td>26.826607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24</td>\n",
       "      <td>28.471765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>33.491146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>22</td>\n",
       "      <td>38.225673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>44.824039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>23</td>\n",
       "      <td>45.734452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>61.049196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>64.865973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>76.746152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>81.907129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>98.121113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>213.208232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>291.372331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>6480.213827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>169</td>\n",
       "      <td>81573.741167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>176</td>\n",
       "      <td>258278.501352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Feature       Variance\n",
       "34     189       5.016506\n",
       "27      47       5.341693\n",
       "33     188       5.665210\n",
       "26      43       6.671609\n",
       "30      50       7.573311\n",
       "23      40       8.600988\n",
       "28      48       8.970383\n",
       "19      32      10.101856\n",
       "25      42      10.697524\n",
       "22      39      12.165576\n",
       "29      49      13.318558\n",
       "20      34      15.074382\n",
       "16      29      16.622048\n",
       "21      38      17.024494\n",
       "24      41      17.610304\n",
       "18      31      18.511246\n",
       "14      27      18.682756\n",
       "13      26      20.194909\n",
       "17      30      20.316810\n",
       "15      28      26.826607\n",
       "11      24      28.471765\n",
       "12      25      33.491146\n",
       "9       22      38.225673\n",
       "8       21      44.824039\n",
       "10      23      45.734452\n",
       "7       20      61.049196\n",
       "6       19      64.865973\n",
       "4       17      76.746152\n",
       "5       18      81.907129\n",
       "3       16      98.121113\n",
       "2       15     213.208232\n",
       "1       14     291.372331\n",
       "0       13    6480.213827\n",
       "31     169   81573.741167\n",
       "32     176  258278.501352"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\02gsh\\Desktop\\final_features_read.csv')\n",
    "\n",
    "X = df.drop(['ID', 'labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "vth = VarianceThreshold(threshold=5)  # as default threshold=0\n",
    "vth.fit(X)\n",
    "X_vth = X.iloc[:, vth.get_support()]\n",
    "\n",
    "# Calculate variances for the reduced X_train_vth\n",
    "selected_variances = [var for var, selected in zip(vth.variances_, vth.get_support()) if selected]\n",
    "\n",
    "# Create DataFrame for X_train_vth with variances of selected features\n",
    "pd.DataFrame({'Feature': X_vth.columns, 'Variance': selected_variances}).sort_values('Variance', ascending=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "354c9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the 'ID' and 'labels' DataFrame\n",
    "df_id_label_reset = df[['ID', 'labels']].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the 'ID' and 'labels' DataFrame with the selected features DataFrame\n",
    "selected_features_df = pd.concat([df_id_label_reset, X_vth], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c0425d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows containing any missing values\n",
    "df_cleaned = selected_features_df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('your_output_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f30f47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 1s 7ms/step - loss: 1.5064 - accuracy: 0.3038 - val_loss: 1.3555 - val_accuracy: 0.6299\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.3643 - accuracy: 0.4902 - val_loss: 1.3155 - val_accuracy: 0.6562\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2951 - accuracy: 0.5991 - val_loss: 1.2690 - val_accuracy: 0.6772\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2532 - accuracy: 0.6463 - val_loss: 1.2126 - val_accuracy: 0.6877\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.2110 - accuracy: 0.6647 - val_loss: 1.1514 - val_accuracy: 0.6929\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1630 - accuracy: 0.6654 - val_loss: 1.0867 - val_accuracy: 0.7008\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.1135 - accuracy: 0.6772 - val_loss: 1.0300 - val_accuracy: 0.6929\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.0518 - accuracy: 0.6798 - val_loss: 0.9611 - val_accuracy: 0.7087\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9948 - accuracy: 0.6923 - val_loss: 0.8795 - val_accuracy: 0.7113\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 0.9557 - accuracy: 0.6896 - val_loss: 0.8071 - val_accuracy: 0.7244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c9ad045510>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your CSV file (replace 'path_to_your_file/your_file.csv' with the actual path)\n",
    "file_path =r\"C:\\Users\\02gsh\\Desktop\\pd\\codes\\your_output_file.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming your CSV file has columns/features and a target column named 'parkinson_stage'\n",
    "X = df.drop(['ID', 'labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Preprocess the data (standardization and label encoding)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'), \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Adjust the number of neurons for the output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "84b9ae65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98/98 [==============================] - 1s 5ms/step - loss: 1.4504 - accuracy: 0.3889 - val_loss: 1.3268 - val_accuracy: 0.6005\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.3028 - accuracy: 0.5727 - val_loss: 1.2590 - val_accuracy: 0.5941\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.2255 - accuracy: 0.6002 - val_loss: 1.1594 - val_accuracy: 0.5915\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.1343 - accuracy: 0.6031 - val_loss: 1.0489 - val_accuracy: 0.5915\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0851 - accuracy: 0.6111 - val_loss: 0.9907 - val_accuracy: 0.5915\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 1.0424 - accuracy: 0.6114 - val_loss: 0.9271 - val_accuracy: 0.6005\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9873 - accuracy: 0.6248 - val_loss: 0.8664 - val_accuracy: 0.6453\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9563 - accuracy: 0.6380 - val_loss: 0.8241 - val_accuracy: 0.6569\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.9234 - accuracy: 0.6450 - val_loss: 0.7740 - val_accuracy: 0.6697\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8778 - accuracy: 0.6546 - val_loss: 0.7421 - val_accuracy: 0.6812\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8598 - accuracy: 0.6578 - val_loss: 0.7027 - val_accuracy: 0.7004\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8218 - accuracy: 0.6681 - val_loss: 0.6800 - val_accuracy: 0.7068\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.8055 - accuracy: 0.6735 - val_loss: 0.6451 - val_accuracy: 0.7401\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.7841 - accuracy: 0.6885 - val_loss: 0.6405 - val_accuracy: 0.7337\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7690 - accuracy: 0.6889 - val_loss: 0.6138 - val_accuracy: 0.7478\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.7364 - accuracy: 0.6943 - val_loss: 0.6044 - val_accuracy: 0.7618\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.7001 - val_loss: 0.5779 - val_accuracy: 0.7759\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.7168 - accuracy: 0.7033 - val_loss: 0.5715 - val_accuracy: 0.7785\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.7021 - accuracy: 0.7113 - val_loss: 0.5513 - val_accuracy: 0.7977\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.7209 - val_loss: 0.5343 - val_accuracy: 0.7977\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.7254 - val_loss: 0.5110 - val_accuracy: 0.8105\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6608 - accuracy: 0.7273 - val_loss: 0.5013 - val_accuracy: 0.8297\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7407 - val_loss: 0.4904 - val_accuracy: 0.8284\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7506 - val_loss: 0.4725 - val_accuracy: 0.8399\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6058 - accuracy: 0.7583 - val_loss: 0.4580 - val_accuracy: 0.8476\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.7698 - val_loss: 0.4384 - val_accuracy: 0.8528\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5797 - accuracy: 0.7724 - val_loss: 0.4458 - val_accuracy: 0.8476\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5552 - accuracy: 0.7923 - val_loss: 0.4289 - val_accuracy: 0.8745\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5561 - accuracy: 0.7907 - val_loss: 0.4127 - val_accuracy: 0.8643\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7993 - val_loss: 0.4042 - val_accuracy: 0.8694\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5189 - accuracy: 0.8073 - val_loss: 0.4025 - val_accuracy: 0.8681\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.8019 - val_loss: 0.3995 - val_accuracy: 0.8592\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8105 - val_loss: 0.4054 - val_accuracy: 0.8745\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8124 - val_loss: 0.3845 - val_accuracy: 0.8732\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8201 - val_loss: 0.3826 - val_accuracy: 0.8745\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8092 - val_loss: 0.3768 - val_accuracy: 0.8758\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.8079 - val_loss: 0.3548 - val_accuracy: 0.8822\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8246 - val_loss: 0.3984 - val_accuracy: 0.8796\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.8204 - val_loss: 0.4005 - val_accuracy: 0.8822\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.8364 - val_loss: 0.3883 - val_accuracy: 0.8668\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8342 - val_loss: 0.3648 - val_accuracy: 0.8822\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4502 - accuracy: 0.8358 - val_loss: 0.3773 - val_accuracy: 0.8848\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.8448 - val_loss: 0.3868 - val_accuracy: 0.8796\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4416 - accuracy: 0.8393 - val_loss: 0.3965 - val_accuracy: 0.8694\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8515 - val_loss: 0.3870 - val_accuracy: 0.8617\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4181 - accuracy: 0.8502 - val_loss: 0.3754 - val_accuracy: 0.8720\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8480 - val_loss: 0.3575 - val_accuracy: 0.8822\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4111 - accuracy: 0.8518 - val_loss: 0.4031 - val_accuracy: 0.8822\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8473 - val_loss: 0.3785 - val_accuracy: 0.8835\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8550 - val_loss: 0.3716 - val_accuracy: 0.8873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c9c6b83cd0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\02gsh\\Desktop\\csv_combined_all.csv')\n",
    "\n",
    "X = df.drop(['labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Apply VarianceThreshold feature selection\n",
    "vth = VarianceThreshold(threshold=5)\n",
    "vth.fit(X)\n",
    "X_vth = X.iloc[:, vth.get_support()]\n",
    "\n",
    "# Perform oversampling to balance the classes\n",
    "#ros = RandomOverSampler(random_state=42)\n",
    "#X_resampled, y_resampled = ros.fit_resample(X_vth, y)\n",
    "\n",
    "# Calculate variances for the reduced X_train_vth\n",
    "selected_variances = [var for var, selected in zip(vth.variances_, vth.get_support()) if selected]\n",
    "\n",
    "# Reset the index of the 'ID' and 'labels' DataFrame\n",
    "df_id_label_reset = df[['labels']].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the 'ID' and 'labels' DataFrame with the selected features DataFrame\n",
    "selected_features_df = pd.concat([df_id_label_reset, X_vth], axis=1)\n",
    "\n",
    "# Drop rows containing any missing values\n",
    "df_cleaned = selected_features_df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('oversampled_your_output_file.csv', index=False)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your CSV file (replace 'path_to_your_file/your_file.csv' with the actual path)\n",
    "file_path = r\"C:\\Users\\02gsh\\Desktop\\pd\\codes\\oversampled_your_output_file.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming your CSV file has columns/features and a target column named 'labels'\n",
    "X = df.drop(['labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Perform oversampling to balance the classes\n",
    "#ros = RandomOverSampler(random_state=42)\n",
    "#X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Preprocess the data (standardization and label encoding)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'), \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Adjust the number of neurons for the output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a2187e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "236/236 [==============================] - 2s 4ms/step - loss: 1.4603 - accuracy: 0.2954 - val_loss: 1.3073 - val_accuracy: 0.4457\n",
      "Epoch 2/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.2595 - accuracy: 0.3816 - val_loss: 1.1158 - val_accuracy: 0.4780\n",
      "Epoch 3/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1536 - accuracy: 0.4282 - val_loss: 1.0624 - val_accuracy: 0.5082\n",
      "Epoch 4/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1078 - accuracy: 0.4429 - val_loss: 1.0218 - val_accuracy: 0.5607\n",
      "Epoch 5/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0813 - accuracy: 0.4533 - val_loss: 0.9994 - val_accuracy: 0.6004\n",
      "Epoch 6/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0705 - accuracy: 0.4807 - val_loss: 0.9844 - val_accuracy: 0.5660\n",
      "Epoch 7/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0447 - accuracy: 0.4905 - val_loss: 0.9654 - val_accuracy: 0.5750\n",
      "Epoch 8/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0284 - accuracy: 0.4905 - val_loss: 0.9439 - val_accuracy: 0.5840\n",
      "Epoch 9/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0168 - accuracy: 0.5115 - val_loss: 0.9527 - val_accuracy: 0.5692\n",
      "Epoch 10/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0104 - accuracy: 0.5092 - val_loss: 0.9250 - val_accuracy: 0.5882\n",
      "Epoch 11/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9838 - accuracy: 0.5276 - val_loss: 0.8814 - val_accuracy: 0.6328\n",
      "Epoch 12/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9609 - accuracy: 0.5455 - val_loss: 0.8844 - val_accuracy: 0.6550\n",
      "Epoch 13/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9523 - accuracy: 0.5552 - val_loss: 0.8247 - val_accuracy: 0.6672\n",
      "Epoch 14/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9601 - accuracy: 0.5537 - val_loss: 0.8657 - val_accuracy: 0.6789\n",
      "Epoch 15/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9338 - accuracy: 0.5683 - val_loss: 0.8364 - val_accuracy: 0.6868\n",
      "Epoch 16/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9157 - accuracy: 0.5875 - val_loss: 0.8235 - val_accuracy: 0.7043\n",
      "Epoch 17/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9178 - accuracy: 0.5899 - val_loss: 0.8171 - val_accuracy: 0.6937\n",
      "Epoch 18/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9004 - accuracy: 0.6004 - val_loss: 0.8137 - val_accuracy: 0.7085\n",
      "Epoch 19/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8762 - accuracy: 0.6144 - val_loss: 0.7454 - val_accuracy: 0.7244\n",
      "Epoch 20/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8977 - accuracy: 0.6032 - val_loss: 0.7939 - val_accuracy: 0.6974\n",
      "Epoch 21/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8532 - accuracy: 0.6342 - val_loss: 0.7994 - val_accuracy: 0.7186\n",
      "Epoch 22/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8767 - accuracy: 0.6311 - val_loss: 0.7416 - val_accuracy: 0.7207\n",
      "Epoch 23/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8370 - accuracy: 0.6477 - val_loss: 0.7241 - val_accuracy: 0.7403\n",
      "Epoch 24/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8415 - accuracy: 0.6489 - val_loss: 0.7876 - val_accuracy: 0.6990\n",
      "Epoch 25/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8524 - accuracy: 0.6372 - val_loss: 0.7359 - val_accuracy: 0.7308\n",
      "Epoch 26/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8202 - accuracy: 0.6550 - val_loss: 0.7450 - val_accuracy: 0.7250\n",
      "Epoch 27/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8218 - accuracy: 0.6587 - val_loss: 0.7428 - val_accuracy: 0.7308\n",
      "Epoch 28/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8363 - accuracy: 0.6464 - val_loss: 0.7491 - val_accuracy: 0.7303\n",
      "Epoch 29/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8213 - accuracy: 0.6599 - val_loss: 0.7055 - val_accuracy: 0.7589\n",
      "Epoch 30/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8389 - accuracy: 0.6539 - val_loss: 0.7462 - val_accuracy: 0.7266\n",
      "Epoch 31/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8400 - accuracy: 0.6456 - val_loss: 0.7117 - val_accuracy: 0.7446\n",
      "Epoch 32/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8029 - accuracy: 0.6696 - val_loss: 0.6918 - val_accuracy: 0.7583\n",
      "Epoch 33/50\n",
      "236/236 [==============================] - 1s 4ms/step - loss: 0.8060 - accuracy: 0.6774 - val_loss: 0.7832 - val_accuracy: 0.7075\n",
      "Epoch 34/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8275 - accuracy: 0.6587 - val_loss: 0.6753 - val_accuracy: 0.7499\n",
      "Epoch 35/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7753 - accuracy: 0.6880 - val_loss: 0.6491 - val_accuracy: 0.7727\n",
      "Epoch 36/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7610 - accuracy: 0.7013 - val_loss: 0.6967 - val_accuracy: 0.7467\n",
      "Epoch 37/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7633 - accuracy: 0.6961 - val_loss: 0.6449 - val_accuracy: 0.7711\n",
      "Epoch 38/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7932 - accuracy: 0.6908 - val_loss: 0.6333 - val_accuracy: 0.7727\n",
      "Epoch 39/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7721 - accuracy: 0.6978 - val_loss: 0.6355 - val_accuracy: 0.7795\n",
      "Epoch 40/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7559 - accuracy: 0.7027 - val_loss: 0.6782 - val_accuracy: 0.7573\n",
      "Epoch 41/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7650 - accuracy: 0.6994 - val_loss: 0.6439 - val_accuracy: 0.7764\n",
      "Epoch 42/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7390 - accuracy: 0.7176 - val_loss: 0.6487 - val_accuracy: 0.7748\n",
      "Epoch 43/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7279 - accuracy: 0.7161 - val_loss: 0.5943 - val_accuracy: 0.7923\n",
      "Epoch 44/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7358 - accuracy: 0.7137 - val_loss: 0.6454 - val_accuracy: 0.7711\n",
      "Epoch 45/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7143 - accuracy: 0.7227 - val_loss: 0.5863 - val_accuracy: 0.7976\n",
      "Epoch 46/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7539 - accuracy: 0.7112 - val_loss: 0.6575 - val_accuracy: 0.7557\n",
      "Epoch 47/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7668 - accuracy: 0.6913 - val_loss: 0.6239 - val_accuracy: 0.7870\n",
      "Epoch 48/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7297 - accuracy: 0.7141 - val_loss: 0.6371 - val_accuracy: 0.7748\n",
      "Epoch 49/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7045 - accuracy: 0.7276 - val_loss: 0.5977 - val_accuracy: 0.7907\n",
      "Epoch 50/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7265 - accuracy: 0.7225 - val_loss: 0.6188 - val_accuracy: 0.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c9c6c126e0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your CSV file (replace 'path_to_your_file/your_file.csv' with the actual path)\n",
    "file_path = r'C:\\Users\\02gsh\\Desktop\\csv_combined_all.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming your CSV file has columns/features and a target column named 'labels'\n",
    "X = df.drop(['labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Perform oversampling to balance the classes\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Preprocess the data (standardization and label encoding)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'), \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Adjust the number of neurons for the output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "75ab8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "236/236 [==============================] - 2s 4ms/step - loss: 1.4009 - accuracy: 0.2758 - val_loss: 1.3625 - val_accuracy: 0.4849\n",
      "Epoch 2/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.3272 - accuracy: 0.3287 - val_loss: 1.1871 - val_accuracy: 0.5877\n",
      "Epoch 3/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.1617 - accuracy: 0.4205 - val_loss: 0.8908 - val_accuracy: 0.6550\n",
      "Epoch 4/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 1.0037 - accuracy: 0.5087 - val_loss: 0.7690 - val_accuracy: 0.7032\n",
      "Epoch 5/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.9125 - accuracy: 0.5454 - val_loss: 0.6521 - val_accuracy: 0.6640\n",
      "Epoch 6/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.8553 - accuracy: 0.5678 - val_loss: 0.5978 - val_accuracy: 0.6746\n",
      "Epoch 7/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7956 - accuracy: 0.5910 - val_loss: 0.5469 - val_accuracy: 0.6905\n",
      "Epoch 8/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7619 - accuracy: 0.6030 - val_loss: 0.5165 - val_accuracy: 0.7679\n",
      "Epoch 9/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7249 - accuracy: 0.6272 - val_loss: 0.4971 - val_accuracy: 0.7022\n",
      "Epoch 10/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.7046 - accuracy: 0.6282 - val_loss: 0.4788 - val_accuracy: 0.7117\n",
      "Epoch 11/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6787 - accuracy: 0.6476 - val_loss: 0.4590 - val_accuracy: 0.7165\n",
      "Epoch 12/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6678 - accuracy: 0.6546 - val_loss: 0.4540 - val_accuracy: 0.7223\n",
      "Epoch 13/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6532 - accuracy: 0.6570 - val_loss: 0.4403 - val_accuracy: 0.8548\n",
      "Epoch 14/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6385 - accuracy: 0.6702 - val_loss: 0.4312 - val_accuracy: 0.8617\n",
      "Epoch 15/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6386 - accuracy: 0.6664 - val_loss: 0.4173 - val_accuracy: 0.8696\n",
      "Epoch 16/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6163 - accuracy: 0.6842 - val_loss: 0.4084 - val_accuracy: 0.8755\n",
      "Epoch 17/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6079 - accuracy: 0.6863 - val_loss: 0.4062 - val_accuracy: 0.8861\n",
      "Epoch 18/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.6106 - accuracy: 0.6794 - val_loss: 0.4083 - val_accuracy: 0.8283\n",
      "Epoch 19/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5942 - accuracy: 0.6921 - val_loss: 0.4032 - val_accuracy: 0.8786\n",
      "Epoch 20/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5944 - accuracy: 0.7039 - val_loss: 0.3904 - val_accuracy: 0.8898\n",
      "Epoch 21/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5966 - accuracy: 0.6936 - val_loss: 0.4053 - val_accuracy: 0.8855\n",
      "Epoch 22/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5902 - accuracy: 0.6953 - val_loss: 0.3894 - val_accuracy: 0.8887\n",
      "Epoch 23/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5855 - accuracy: 0.7124 - val_loss: 0.3879 - val_accuracy: 0.8723\n",
      "Epoch 24/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5592 - accuracy: 0.7127 - val_loss: 0.3425 - val_accuracy: 0.8961\n",
      "Epoch 25/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5808 - accuracy: 0.7088 - val_loss: 0.3635 - val_accuracy: 0.8988\n",
      "Epoch 26/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5638 - accuracy: 0.7211 - val_loss: 0.3442 - val_accuracy: 0.8993\n",
      "Epoch 27/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5541 - accuracy: 0.7284 - val_loss: 0.3218 - val_accuracy: 0.9099\n",
      "Epoch 28/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5474 - accuracy: 0.7307 - val_loss: 0.3090 - val_accuracy: 0.9221\n",
      "Epoch 29/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5446 - accuracy: 0.7327 - val_loss: 0.3012 - val_accuracy: 0.9104\n",
      "Epoch 30/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5378 - accuracy: 0.7495 - val_loss: 0.2981 - val_accuracy: 0.9014\n",
      "Epoch 31/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5284 - accuracy: 0.7596 - val_loss: 0.3027 - val_accuracy: 0.9126\n",
      "Epoch 32/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7638 - val_loss: 0.2618 - val_accuracy: 0.9184\n",
      "Epoch 33/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5154 - accuracy: 0.7677 - val_loss: 0.2922 - val_accuracy: 0.9078\n",
      "Epoch 34/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5075 - accuracy: 0.7702 - val_loss: 0.2635 - val_accuracy: 0.9126\n",
      "Epoch 35/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.5111 - accuracy: 0.7761 - val_loss: 0.2688 - val_accuracy: 0.9110\n",
      "Epoch 36/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4899 - accuracy: 0.7854 - val_loss: 0.2755 - val_accuracy: 0.9184\n",
      "Epoch 37/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4859 - accuracy: 0.7962 - val_loss: 0.2670 - val_accuracy: 0.9126\n",
      "Epoch 38/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4810 - accuracy: 0.7967 - val_loss: 0.2452 - val_accuracy: 0.9263\n",
      "Epoch 39/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4767 - accuracy: 0.7910 - val_loss: 0.2445 - val_accuracy: 0.9216\n",
      "Epoch 40/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4786 - accuracy: 0.7964 - val_loss: 0.2446 - val_accuracy: 0.9253\n",
      "Epoch 41/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.5032 - accuracy: 0.7910 - val_loss: 0.2505 - val_accuracy: 0.9332\n",
      "Epoch 42/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4750 - accuracy: 0.8038 - val_loss: 0.2566 - val_accuracy: 0.9258\n",
      "Epoch 43/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4718 - accuracy: 0.7984 - val_loss: 0.2425 - val_accuracy: 0.9221\n",
      "Epoch 44/50\n",
      "236/236 [==============================] - 1s 3ms/step - loss: 0.4537 - accuracy: 0.8114 - val_loss: 0.2108 - val_accuracy: 0.9406\n",
      "Epoch 45/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4438 - accuracy: 0.8219 - val_loss: 0.2126 - val_accuracy: 0.9375\n",
      "Epoch 46/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4599 - accuracy: 0.8133 - val_loss: 0.2069 - val_accuracy: 0.9285\n",
      "Epoch 47/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4451 - accuracy: 0.8125 - val_loss: 0.2172 - val_accuracy: 0.9406\n",
      "Epoch 48/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4419 - accuracy: 0.8182 - val_loss: 0.2032 - val_accuracy: 0.9401\n",
      "Epoch 49/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4317 - accuracy: 0.8212 - val_loss: 0.1825 - val_accuracy: 0.9433\n",
      "Epoch 50/50\n",
      "236/236 [==============================] - 1s 2ms/step - loss: 0.4416 - accuracy: 0.8155 - val_loss: 0.1891 - val_accuracy: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1c9ae695c60>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\02gsh\\Desktop\\csv_combined_all.csv')\n",
    "\n",
    "X = df.drop(['labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Apply VarianceThreshold feature selection\n",
    "vth = VarianceThreshold(threshold=5)\n",
    "vth.fit(X)\n",
    "X_vth = X.iloc[:, vth.get_support()]\n",
    "\n",
    "# Calculate variances for the reduced X_train_vth\n",
    "selected_variances = [var for var, selected in zip(vth.variances_, vth.get_support()) if selected]\n",
    "\n",
    "# Reset the index of the 'ID' and 'labels' DataFrame\n",
    "df_id_label_reset = df[['labels']].reset_index(drop=True)\n",
    "\n",
    "# Concatenate the 'ID' and 'labels' DataFrame with the selected features DataFrame\n",
    "selected_features_df = pd.concat([df_id_label_reset, X_vth], axis=1)\n",
    "\n",
    "# Drop rows containing any missing values\n",
    "df_cleaned = selected_features_df.dropna()\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df_cleaned.to_csv('oversampled_your_output_file.csv', index=False)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load your CSV file (replace 'path_to_your_file/your_file.csv' with the actual path)\n",
    "file_path = r\"C:\\Users\\02gsh\\Desktop\\pd\\codes\\oversampled_your_output_file.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Assuming your CSV file has columns/features and a target column named 'labels'\n",
    "X = df.drop(['labels'], axis=1)\n",
    "y = df['labels']\n",
    "\n",
    "# Perform oversampling to balance the classes\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X, y = ros.fit_resample(X, y)\n",
    "\n",
    "# Preprocess the data (standardization and label encoding)\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the DNN model\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(x_train.shape[1],), activation='relu'), \n",
    "    Dense(32, activation='relu'),  \n",
    "    Dropout(0.5),\n",
    "    Dense(16, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(8, activation='relu'), \n",
    "    Dropout(0.5),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')  # Adjust the number of neurons for the output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=32, validation_data=(x_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77c53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
